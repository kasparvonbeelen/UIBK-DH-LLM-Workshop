{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Tq0pWVJXoo10"
      ],
      "authorship_tag": "ABX9TyO5UGl5+a7WA1RgkimA8fus",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasparvonbeelen/UIBK-DH-LLM-Workshop/blob/dev/LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using open-source LLMs for analysing humanities data"
      ],
      "metadata": {
        "id": "S-2ldxb0iUxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you are using a [GPU](https://cloud.google.com/gpu) when running the code below.\n",
        "\n",
        "Inspired by: https://huggingface.co/learn/cookbook/structured_generation\n",
        "\n",
        "And\n",
        "\n",
        "Go to **`Runtime`** and select **`Change runtime type`**, then select `T4 GPU` (or any other GPU available)"
      ],
      "metadata": {
        "id": "E_e5BL9Ti3JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the transformer libraries\n",
        "!pip install -q -U \"transformers==4.40.0\" pydantic accelerate outlines datasets --upgrade"
      ],
      "metadata": {
        "id": "qxa9ES0zX9ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09a9fc0-c0e2-49c3-cadf-d70ac730b57d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 50)"
      ],
      "metadata": {
        "id": "y6sCVCZiWAGW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "KIuiPmuRV9aU",
        "outputId": "2c4f68f4-f825-479a-854c-8192d978bc50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "llm_client = InferenceClient(model=repo_id, timeout=120)\n",
        "\n",
        "# Test your LLM client\n",
        "#llm_client.text_generation(prompt=\"How are you today?\", max_new_tokens=20)"
      ],
      "metadata": {
        "id": "RDZqWyP1IASN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llm_client.chat_completion(messages=messages)"
      ],
      "metadata": {
        "id": "4sKYi5cILToK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # disable warning"
      ],
      "metadata": {
        "id": "IivyFPPNQ0t-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "27FpdOCLasrJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device = 'cuda' # make sure you use a GPU"
      ],
      "metadata": {
        "id": "Uc9ROzqBjxan"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/kasparvonbeelen/lancaster-newspaper-workshop/wc/data/subsample500mixedocr-selected_mitch.csv')\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "bj-797e0Z9zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "68fdfc3e-aa3a-45e3-80f6-50ab791238fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   publication_code  issue_id  item_id  \\\n",
              "0              2249       624  art0017   \n",
              "1              2250       908  art0002   \n",
              "2              2250       406  art0024   \n",
              "\n",
              "                                newspaper_title  \\\n",
              "0                                 The Bee-Hive.   \n",
              "1  The Industrial Review, Social and Political.   \n",
              "2  The Industrial Review, Social and Political.   \n",
              "\n",
              "                                      data_provider        date  year  month  \\\n",
              "0  British Library Heritage Made Digital Newspapers  1871-06-24  1871      6   \n",
              "1  British Library Heritage Made Digital Newspapers  1877-09-08  1877      9   \n",
              "2  British Library Heritage Made Digital Newspapers  1878-04-06  1878      4   \n",
              "\n",
              "   day         location  word_count  ocrquality political_leaning_label  \\\n",
              "0   24  London, England         271      0.9098                 liberal   \n",
              "1    8  London, England        2791      0.9841                 liberal   \n",
              "2    6  London, England         304      0.9870                 liberal   \n",
              "\n",
              "  price_label                                               text  \n",
              "0          1d  THE TICHBORNE CASE.  On Tuesday, before the So...  \n",
              "1          2d  THE CLERGY AND TRADE UNIONS.  LETTER FROM REV....  \n",
              "2          2d  INDUSTRIAL REVIEW  OUR LEGISLATORS.  THE unrul...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6869d9e-609f-45ad-a49d-1e5148190922\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publication_code</th>\n",
              "      <th>issue_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>newspaper_title</th>\n",
              "      <th>data_provider</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>location</th>\n",
              "      <th>word_count</th>\n",
              "      <th>ocrquality</th>\n",
              "      <th>political_leaning_label</th>\n",
              "      <th>price_label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2249</td>\n",
              "      <td>624</td>\n",
              "      <td>art0017</td>\n",
              "      <td>The Bee-Hive.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1871-06-24</td>\n",
              "      <td>1871</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>London, England</td>\n",
              "      <td>271</td>\n",
              "      <td>0.9098</td>\n",
              "      <td>liberal</td>\n",
              "      <td>1d</td>\n",
              "      <td>THE TICHBORNE CASE.  On Tuesday, before the So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2250</td>\n",
              "      <td>908</td>\n",
              "      <td>art0002</td>\n",
              "      <td>The Industrial Review, Social and Political.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1877-09-08</td>\n",
              "      <td>1877</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>London, England</td>\n",
              "      <td>2791</td>\n",
              "      <td>0.9841</td>\n",
              "      <td>liberal</td>\n",
              "      <td>2d</td>\n",
              "      <td>THE CLERGY AND TRADE UNIONS.  LETTER FROM REV....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2250</td>\n",
              "      <td>406</td>\n",
              "      <td>art0024</td>\n",
              "      <td>The Industrial Review, Social and Political.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1878-04-06</td>\n",
              "      <td>1878</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>London, England</td>\n",
              "      <td>304</td>\n",
              "      <td>0.9870</td>\n",
              "      <td>liberal</td>\n",
              "      <td>2d</td>\n",
              "      <td>INDUSTRIAL REVIEW  OUR LEGISLATORS.  THE unrul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6869d9e-609f-45ad-a49d-1e5148190922')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6869d9e-609f-45ad-a49d-1e5148190922 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6869d9e-609f-45ad-a49d-1e5148190922');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07dc7ffd-b7b8-4cb3-8280-57ae9a79ebed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07dc7ffd-b7b8-4cb3-8280-57ae9a79ebed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07dc7ffd-b7b8-4cb3-8280-57ae9a79ebed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"publication_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 192,\n        \"min\": 2249,\n        \"max\": 3408,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          2597,\n          2619,\n          2979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 340,\n        \"min\": 101,\n        \"max\": 1230,\n        \"num_unique_values\": 269,\n        \"samples\": [\n          1123,\n          328,\n          415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 160,\n        \"samples\": [\n          \"art0102\",\n          \"art0057\",\n          \"art0130\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newspaper_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 73,\n        \"samples\": [\n          \"The Warrington Examiner.\",\n          \"Denton Examiner, Audenshaw, Hooley Hill and Dukinfield Advertiser.\",\n          \"The Northern News.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_provider\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"British Library Living with Machines Project\",\n          \"British Library Heritage Made Digital Newspapers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 481,\n        \"samples\": [\n          \"1889-10-16\",\n          \"1916-02-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 1845,\n        \"max\": 1920,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          1893,\n          1905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          25,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"Brighouse, West Yorkshire, England\",\n          \"Dewsbury, West Yorkshire, England\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 892,\n        \"min\": 0,\n        \"max\": 6127,\n        \"num_unique_values\": 346,\n        \"samples\": [\n          970,\n          3004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocrquality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1559452514514646,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 449,\n        \"samples\": [\n          0.7861,\n          0.8926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"political_leaning_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"independent\",\n          \"unionist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"3 \\u00bd d<SEP>1d\",\n          \"4 \\u00bd d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"NORTHERN WEEKLY GAZETTE: \",\n          \"BIRTHS.  May 23, at 3, Lower Trafalgar.terrace, Swansea, the wife of raptsin W. H. Smith. of a daughter. May 25, nt 6. Cantl,--quare, Swansea. the wife of Mr. T. F. Mathews, of a daughter. May 23. at Preset,.lra. Heath, the wife of Captain Herrick Palmer. of a eon. May 19, at 14, Victoria-terrace, Heath. the wife ef Mr. H. B. Thomas, of a son.  MARRIAGES. May 22, at qt Mary's Church, Swansea (by license), Mr Robert Tucker, of London, to Miss Thomas, of th Red House. St Thomas. Swansea. May 26, at the same church, by the RAY E. B Squire, vicar, William Francis. mariner, to Mary Williams, both of Swansea. At the ,ame time and place, and by the same clergy man. David Barnett, mariner, to Ann Davies, both of 114;h\\u2014street, Swansea. At the same timeand place. Thomas Russell. mariner, to Caroline Bode, both of Bethesda-terrace. Swansea. MI 21, as the Pariah Church. Chittlehampon. by th. Re\\u2022 C. M. Drake. vicar, Mr John Mules, former, of Southmelton, to Marv. youngest d ,nghter of Mr William Rees, late of Park-stre\\u2022 t. q warms May IS, at Resolven Church, by the Rev G. Griffiths, vicrtr. Mr Llewellyn Powell. of Argoed, to Miss Ann Jtnkins. of Forchgoch farm, Raengwrach. May 18 (by license) at Taibach Chapel of Ease, by the Rev E. Phillips. curate of Montana, Mr John Courtis DIVIC.I, son of the late Mr Thomas Davies, of Westfield House, Aberavon, to Miss Marg tret Meyrck, of Tat)), ch. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the purposes of this exercise, we remove both very short and long documents from the dataset\n",
        "df = df[df.word_count.between(10,250)].reset_index()\n",
        "df.shape"
      ],
      "metadata": {
        "id": "gaf2ZEPWpkdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386113f4-03db-4b3f-9c32-8fbe194e9c77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(212, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Hugging Face Hub\n",
        "\n",
        "In the example below, we will experiment with Llama-3-8B, a recent series of open-source LLMs created by Meta. To use Llama3 you need to:\n",
        "\n",
        "- Make an account on Hugging Face https://huggingface.co/\n",
        "- Go to the Llama-3-8B and sign the terms of use you should get a reply swiftly https://huggingface.co/meta-llama/Meta-Llama-3-8B\n",
        "- Create a user access token with read access: https://huggingface.co/docs/hub/en/security-tokens\n",
        "- Run the code cell below to log into the Hugging Face hub. Copy-paste the access token\n",
        "- Reply `n` to the question 'Add token as git credential? (Y/n)'"
      ],
      "metadata": {
        "id": "AZ6LGyYkkYff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnTdsILcavow",
        "outputId": "0de4c357-01b1-4005-eb99-46d24c757457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the LLM model"
      ],
      "metadata": {
        "id": "2NNKw2Rknc2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # define the model, we use the instruct variant\n",
        "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# # instantiate a text generation pipeline\n",
        "# pipeline = transformers.pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=checkpoint,\n",
        "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "#     device=\"cuda\",\n",
        "# )\n",
        "\n",
        "# # some fluff to improve the generation\n",
        "# terminators = [\n",
        "#     pipeline.tokenizer.eos_token_id,\n",
        "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "# ]\n"
      ],
      "metadata": {
        "id": "K3dS2EoMTnny"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting\n",
        "\n",
        "System message: describe how you want to the LLM to work, the behaviour you want it to exhibit\n",
        "User message: Content you want to process (or the LLM to act on).\n",
        "\n",
        "```python\n",
        "messages [\n",
        "  {\n",
        "    \"role\" : \"system\",\n",
        "    \"content\": \"<system prompt here>\"\n",
        "  },\n",
        "  {\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": \"<user prompt here>\"\n",
        "  }\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "QY1ucJhFnguw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a message by articulating a system and user prompt."
      ],
      "metadata": {
        "id": "GNYCb3IqoRZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "          You are an helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "          Read the newspaper articles attentively and extract the required information.\n",
        "          Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "          Don't make thigs up! If the information is not in the article then just say 'Dunno'\"\"\"\n",
        "              },\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Provide a short description of principal characters portrayed newspaper article?\n",
        "                  ###{df.iloc[0].text}###\"\"\"\n",
        "              }\n",
        "  ]"
      ],
      "metadata": {
        "id": "AO5PEGlsUukK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh2iS37UBIOU",
        "outputId": "e276a1da-1ee9-47ac-8990-873ecc9ae85a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"\\n          You are an helpful AI that will assist me with analysing and reading newspaper articles.\\n          Read the newspaper articles attentively and extract the required information.\\n          Each newspaper article will be enclosed with triple hash tags (i.e. ###).\\n          Don't make thigs up! If the information is not in the article then just say 'Dunno'\"},\n",
              " {'role': 'user',\n",
              "  'content': 'Provide a short description of principal characters portrayed newspaper article?\\n                  ###WOOLISTON.  As UNDISTAICLIC IN DIYVICULTY.—A somewhat singular ease arose at Woolaston, on Monday, in respect to which there were some fears that the interment of the unfortunate mate of the steam tug. Earl of Glamorgan, who was drowned in the Severn a few days ago, would not be allowed to take place without a \"scene.\" It appeared that the parish undertaker had received an order to make a parish coffin, at that time the body not having been recognised. Before, however, the coffin was made it was ascertained who the demised was, and some instructions were given that a \" respectable \" interment should take place, and a coffin befitting the position of the unfortunate man provided. The undertaker accordingly substituted for the parish coffin one of more expensive make, and the body was duly placed therein and screwed down. After the adjourned inquest on Monday, the brother of deceased repudiated the expense, and the ondertiker appealed to the coroner, who was powerless, and the former declared that the body should not be given up until his claims was discharged. ###'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(llm_client.chat_completion)"
      ],
      "metadata": {
        "id": "E0_D-hHTMviq",
        "outputId": "f7893bcd-6433-4a77-df8d-7b02e8b6a6b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method chat_completion in module huggingface_hub.inference._client:\n",
            "\n",
            "chat_completion(messages: List[Dict[str, str]], *, model: Optional[str] = None, stream: bool = False, frequency_penalty: Optional[float] = None, logit_bias: Optional[List[float]] = None, logprobs: Optional[bool] = None, max_tokens: Optional[int] = None, n: Optional[int] = None, presence_penalty: Optional[float] = None, seed: Optional[int] = None, stop: Optional[List[str]] = None, temperature: Optional[float] = None, tool_choice: Union[huggingface_hub.inference._generated.types.chat_completion.ChatCompletionInputToolTypeClass, Literal['OneOf'], NoneType] = None, tool_prompt: Optional[str] = None, tools: Optional[List[huggingface_hub.inference._generated.types.chat_completion.ChatCompletionInputTool]] = None, top_logprobs: Optional[int] = None, top_p: Optional[float] = None) -> Union[huggingface_hub.inference._generated.types.chat_completion.ChatCompletionOutput, Iterable[huggingface_hub.inference._generated.types.chat_completion.ChatCompletionStreamOutput]] method of huggingface_hub.inference._client.InferenceClient instance\n",
            "            A method for completing conversations using a specified language model.\n",
            "    \n",
            "            <Tip>\n",
            "    \n",
            "            If the model is served by a server supporting chat-completion, the method will directly call the server's\n",
            "            `/v1/chat/completions` endpoint. If the server does not support chat-completion, the method will render the\n",
            "            chat template client-side based on the information fetched from the Hub API. In this case, you will need to\n",
            "            have `minijinja` template engine installed. Run `pip install \"huggingface_hub[inference]\"` or `pip install minijinja`\n",
            "            to install it.\n",
            "    \n",
            "            </Tip>\n",
            "    \n",
            "            Args:\n",
            "                messages (List[Union[`SystemMessage`, `UserMessage`, `AssistantMessage`]]):\n",
            "                    Conversation history consisting of roles and content pairs.\n",
            "                model (`str`, *optional*):\n",
            "                    The model to use for chat-completion. Can be a model ID hosted on the Hugging Face Hub or a URL to a deployed\n",
            "                    Inference Endpoint. If not provided, the default recommended model for chat-based text-generation will be used.\n",
            "                    See https://huggingface.co/tasks/text-generation for more details.\n",
            "                frequency_penalty (`float`, *optional*):\n",
            "                    Penalizes new tokens based on their existing frequency\n",
            "                    in the text so far. Range: [-2.0, 2.0]. Defaults to 0.0.\n",
            "                logit_bias (`List[float]`, *optional*):\n",
            "                    Modify the likelihood of specified tokens appearing in the completion. Accepts a JSON object that maps tokens\n",
            "                    (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically,\n",
            "                    the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model,\n",
            "                    but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should\n",
            "                    result in a ban or exclusive selection of the relevant token. Defaults to None.\n",
            "                logprobs (`bool`, *optional*):\n",
            "                    Whether to return log probabilities of the output tokens or not. If true, returns the log\n",
            "                    probabilities of each output token returned in the content of message.\n",
            "                max_tokens (`int`, *optional*):\n",
            "                    Maximum number of tokens allowed in the response. Defaults to 20.\n",
            "                n (`int`, *optional*):\n",
            "                    UNUSED.\n",
            "                presence_penalty (`float`, *optional*):\n",
            "                    Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the\n",
            "                    text so far, increasing the model's likelihood to talk about new topics.\n",
            "                seed (Optional[`int`], *optional*):\n",
            "                    Seed for reproducible control flow. Defaults to None.\n",
            "                stop (Optional[`str`], *optional*):\n",
            "                    Up to four strings which trigger the end of the response.\n",
            "                    Defaults to None.\n",
            "                stream (`bool`, *optional*):\n",
            "                    Enable realtime streaming of responses. Defaults to False.\n",
            "                temperature (`float`, *optional*):\n",
            "                    Controls randomness of the generations. Lower values ensure\n",
            "                    less random completions. Range: [0, 2]. Defaults to 1.0.\n",
            "                top_logprobs (`int`, *optional*):\n",
            "                    An integer between 0 and 5 specifying the number of most likely tokens to return at each token\n",
            "                    position, each with an associated log probability. logprobs must be set to true if this parameter is\n",
            "                    used.\n",
            "                top_p (`float`, *optional*):\n",
            "                    Fraction of the most likely next words to sample from.\n",
            "                    Must be between 0 and 1. Defaults to 1.0.\n",
            "                tool_choice ([`ChatCompletionInputToolTypeClass`] or [`ChatCompletionInputToolTypeEnum`], *optional*):\n",
            "                    The tool to use for the completion. Defaults to \"auto\".\n",
            "                tool_prompt (`str`, *optional*):\n",
            "                    A prompt to be appended before the tools.\n",
            "                tools (List of [`ChatCompletionInputTool`], *optional*):\n",
            "                    A list of tools the model may call. Currently, only functions are supported as a tool. Use this to\n",
            "                    provide a list of functions the model may generate JSON inputs for.\n",
            "    \n",
            "            Returns:\n",
            "                [`ChatCompletionOutput] or Iterable of [`ChatCompletionStreamOutput`]:\n",
            "                Generated text returned from the server:\n",
            "                - if `stream=False`, the generated text is returned as a [`ChatCompletionOutput`] (default).\n",
            "                - if `stream=True`, the generated text is returned token by token as a sequence of [`ChatCompletionStreamOutput`].\n",
            "    \n",
            "            Raises:\n",
            "                [`InferenceTimeoutError`]:\n",
            "                    If the model is unavailable or the request times out.\n",
            "                `HTTPError`:\n",
            "                    If the request fails with an HTTP error status code other than HTTP 503.\n",
            "    \n",
            "            Example:\n",
            "    \n",
            "            ```py\n",
            "            # Chat example\n",
            "            >>> from huggingface_hub import InferenceClient\n",
            "            >>> messages = [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
            "            >>> client = InferenceClient(\"HuggingFaceH4/zephyr-7b-beta\")\n",
            "            >>> client.chat_completion(messages, max_tokens=100)\n",
            "            ChatCompletionOutput(\n",
            "                choices=[\n",
            "                    ChatCompletionOutputComplete(\n",
            "                        finish_reason='eos_token',\n",
            "                        index=0,\n",
            "                        message=ChatCompletionOutputMessage(\n",
            "                            content='The capital of France is Paris. The official name of the city is Ville de Paris (City of Paris) and the name of the country governing body, which is located in Paris, is La République française (The French Republic). \n",
            "    I hope that helps! Let me know if you need any further information.'\n",
            "                        )\n",
            "                    )\n",
            "                ],\n",
            "                created=1710498360\n",
            "            )\n",
            "    \n",
            "            >>> for token in client.chat_completion(messages, max_tokens=10, stream=True):\n",
            "            ...     print(token)\n",
            "            ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(content='The', role='assistant'), index=0, finish_reason=None)], created=1710498504)\n",
            "            ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(content=' capital', role='assistant'), index=0, finish_reason=None)], created=1710498504)\n",
            "            (...)\n",
            "            ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(content=' may', role='assistant'), index=0, finish_reason=None)], created=1710498504)\n",
            "    \n",
            "            # Chat example with tools\n",
            "            >>> client = InferenceClient(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n",
            "            >>> messages = [\n",
            "            ...     {\n",
            "            ...         \"role\": \"system\",\n",
            "            ...         \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\",\n",
            "            ...     },\n",
            "            ...     {\n",
            "            ...         \"role\": \"user\",\n",
            "            ...         \"content\": \"What's the weather like the next 3 days in San Francisco, CA?\",\n",
            "            ...     },\n",
            "            ... ]\n",
            "            >>> tools = [\n",
            "            ...     {\n",
            "            ...         \"type\": \"function\",\n",
            "            ...         \"function\": {\n",
            "            ...             \"name\": \"get_current_weather\",\n",
            "            ...             \"description\": \"Get the current weather\",\n",
            "            ...             \"parameters\": {\n",
            "            ...                 \"type\": \"object\",\n",
            "            ...                 \"properties\": {\n",
            "            ...                     \"location\": {\n",
            "            ...                         \"type\": \"string\",\n",
            "            ...                         \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
            "            ...                     },\n",
            "            ...                     \"format\": {\n",
            "            ...                         \"type\": \"string\",\n",
            "            ...                         \"enum\": [\"celsius\", \"fahrenheit\"],\n",
            "            ...                         \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
            "            ...                     },\n",
            "            ...                 },\n",
            "            ...                 \"required\": [\"location\", \"format\"],\n",
            "            ...             },\n",
            "            ...         },\n",
            "            ...     },\n",
            "            ...     {\n",
            "            ...         \"type\": \"function\",\n",
            "            ...         \"function\": {\n",
            "            ...             \"name\": \"get_n_day_weather_forecast\",\n",
            "            ...             \"description\": \"Get an N-day weather forecast\",\n",
            "            ...             \"parameters\": {\n",
            "            ...                 \"type\": \"object\",\n",
            "            ...                 \"properties\": {\n",
            "            ...                     \"location\": {\n",
            "            ...                         \"type\": \"string\",\n",
            "            ...                         \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
            "            ...                     },\n",
            "            ...                     \"format\": {\n",
            "            ...                         \"type\": \"string\",\n",
            "            ...                         \"enum\": [\"celsius\", \"fahrenheit\"],\n",
            "            ...                         \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
            "            ...                     },\n",
            "            ...                     \"num_days\": {\n",
            "            ...                         \"type\": \"integer\",\n",
            "            ...                         \"description\": \"The number of days to forecast\",\n",
            "            ...                     },\n",
            "            ...                 },\n",
            "            ...                 \"required\": [\"location\", \"format\", \"num_days\"],\n",
            "            ...             },\n",
            "            ...         },\n",
            "            ...     },\n",
            "            ... ]\n",
            "    \n",
            "            >>> response = client.chat_completion(\n",
            "            ...     model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
            "            ...     messages=messages,\n",
            "            ...     tools=tools,\n",
            "            ...     tool_choice=\"auto\",\n",
            "            ...     max_tokens=500,\n",
            "            ... )\n",
            "            >>> response.choices[0].message.tool_calls[0].function\n",
            "            ChatCompletionOutputFunctionDefinition(\n",
            "                arguments={\n",
            "                    'location': 'San Francisco, CA',\n",
            "                    'format': 'fahrenheit',\n",
            "                    'num_days': 3\n",
            "                },\n",
            "                name='get_n_day_weather_forecast',\n",
            "                description=None\n",
            "            )\n",
            "            ```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_completion(messages: list, temperature=.1, top_p=.1) -> str:\n",
        "#   \"\"\"get completion for given system and user prompt\n",
        "#     Arguments:\n",
        "#     messages (list): a list containin a system and user message as\n",
        "#       python dictionaries with keys 'role' and 'content'\n",
        "#     temperature (float): regulate creativity of the text generation\n",
        "#     top_p (float): cummulative probability included in the\n",
        "#       generation process\n",
        "#   \"\"\"\n",
        "#   prompt = pipeline.tokenizer.apply_chat_template(\n",
        "#         messages,\n",
        "#         tokenize=False,\n",
        "#         add_generation_prompt=True\n",
        "#       )\n",
        "\n",
        "#   outputs = pipeline(\n",
        "#     prompt,\n",
        "#     max_new_tokens=256,\n",
        "#     eos_token_id=terminators,\n",
        "#     do_sample=True,\n",
        "#     temperature=temperature,\n",
        "#     top_p=top_p,\n",
        "#       )\n",
        "#   return outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "\n",
        "def get_completion(messages: list, temperature=.1, top_p=.1):\n",
        "    outputs = llm_client.chat_completion(\n",
        "        messages=messages,\n",
        "        max_tokens=256,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "        )\n",
        "    return outputs.choices[0].message.content"
      ],
      "metadata": {
        "id": "-MM2Wlv_Vw3y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6G6Cbt18lUX",
        "outputId": "4ea9a40c-64ad-480e-e965-6e310919e591"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"\\n          You are an helpful AI that will assist me with analysing and reading newspaper articles.\\n          Read the newspaper articles attentively and extract the required information.\\n          Each newspaper article will be enclosed with triple hash tags (i.e. ###).\\n          Don't make thigs up! If the information is not in the article then just say 'Dunno'\"},\n",
              " {'role': 'user',\n",
              "  'content': 'Provide a short description of principal characters portrayed newspaper article?\\n                  ###WOOLISTON.  As UNDISTAICLIC IN DIYVICULTY.—A somewhat singular ease arose at Woolaston, on Monday, in respect to which there were some fears that the interment of the unfortunate mate of the steam tug. Earl of Glamorgan, who was drowned in the Severn a few days ago, would not be allowed to take place without a \"scene.\" It appeared that the parish undertaker had received an order to make a parish coffin, at that time the body not having been recognised. Before, however, the coffin was made it was ascertained who the demised was, and some instructions were given that a \" respectable \" interment should take place, and a coffin befitting the position of the unfortunate man provided. The undertaker accordingly substituted for the parish coffin one of more expensive make, and the body was duly placed therein and screwed down. After the adjourned inquest on Monday, the brother of deceased repudiated the expense, and the ondertiker appealed to the coroner, who was powerless, and the former declared that the body should not be given up until his claims was discharged. ###'}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Z9julPLNiG2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_completion(messages))"
      ],
      "metadata": {
        "id": "RxUuvcWLTjoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3386a07-01be-4acb-c38f-3f03d71fc0b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a short description of the principal characters portrayed in the newspaper article:\n",
            "\n",
            "* The unfortunate mate of the steam tug Earl of Glamorgan, who was drowned in the Severn a few days ago (deceased)\n",
            "* The brother of the deceased\n",
            "* The parish undertaker\n",
            "* The coroner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "- Change the system message and ask the model to reply in medieval French.\n",
        "- Change the user message and ask the model to summarize the article and condense it to one sentence."
      ],
      "metadata": {
        "id": "SML4OsbfXIk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter code here"
      ],
      "metadata": {
        "id": "0CfZ-Q96omxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "Tq0pWVJXoo10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"\"\"\n",
        "    You are an helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper articles attentively and extract the required information.\n",
        "    Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "    Don't make thigs up! Answer in medieval French!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Provide a short description of principal characters portrayed newspaper article?\n",
        "    ###{df.iloc[0].text}###\"\"\"}\n",
        "]\n",
        "\n",
        "print(get_completion(messages))\n"
      ],
      "metadata": {
        "id": "am1Ge38tXGP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dce3933-4d39-44c6-f7cc-1cbfa62d2e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hear ye, hear ye! I shall extract the principal characters from this most singular newspaper article.\n",
            "\n",
            "* Le défunto, or the deceased, is the mate of the steam tug Earl of Glamorgan, who met a watery grave in the Severn a few days prior to the events described in the article.\n",
            "* Le frère, or the brother, of the deceased, who repudiated the expense of the more expensive coffin and refused to relinquish the body until his claims were settled.\n",
            "* Le fossoyeur, or the undertaker, who received the order to prepare a parish coffin, but instead provided a more expensive one at the behest of the authorities. He later appealed to the coroner, who was powerless to intervene.\n",
            "\n",
            "Mayhap these characters shall play a part in the unfolding drama, as the article hints at a \"scene\" that may yet ensue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"\"\"\n",
        "    You are an helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper articles attentively and extract the required information.\n",
        "    Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "    Don't make thigs up! If the information is not in the article then just say 'Dunno'\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Summarize the article content in one sentence.\n",
        "    ###{df.iloc[0].text}###\"\"\"}\n",
        "]\n",
        "\n",
        "print(get_completion(messages))"
      ],
      "metadata": {
        "id": "pBMVp1OQXg3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21386eb2-8a4e-4f0b-e777-15da1c9959c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A body believed to be the mate of the steam tug Earl of Glamorgan, who drowned in the Severn, was initially intended for a parish coffin but was instead given a more expensive one, leading to a dispute over who should pay for the funeral.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying text generation to historical documents\n"
      ],
      "metadata": {
        "id": "gNcYq_a-beX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Summarization"
      ],
      "metadata": {
        "id": "USeWpL8Ar-UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.sample(5, random_state=1984).reset_index(drop=True)\n",
        "df_small"
      ],
      "metadata": {
        "id": "Cw-N3XoUkRfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "1a9b9b2f-f080-403b-a001-bad2e645bcf1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  publication_code  issue_id  item_id  \\\n",
              "0    209              3077       512  art0058   \n",
              "1    352              3040      1210  art0150   \n",
              "2    227              3089       426  art0036   \n",
              "3    293              2974       312  art0014   \n",
              "4    449              3074       818  art0103   \n",
              "\n",
              "                                     newspaper_title  \\\n",
              "0  Nelson Chronicle, Colne Observer, and Clithero...   \n",
              "1  The Birkenhead News and Wirral General Adverti...   \n",
              "2                                   Glasgow Courier.   \n",
              "3  The Stourbridge Observer, Cradley Heath, Hales...   \n",
              "4                  The North-Eastern Weekly Gazette.   \n",
              "\n",
              "                                  data_provider        date  year  month  day  \\\n",
              "0  British Library Living with Machines Project  1899-05-12  1899      5   12   \n",
              "1  British Library Living with Machines Project  1910-12-10  1910     12   10   \n",
              "2  British Library Living with Machines Project  1855-04-26  1855      4   26   \n",
              "3  British Library Living with Machines Project  1887-03-12  1887      3   12   \n",
              "4  British Library Living with Machines Project  1894-08-18  1894      8   18   \n",
              "\n",
              "                               location  word_count  ocrquality  \\\n",
              "0           Nelson, Lancashire, England         160      0.9748   \n",
              "1       Birkenhead, Merseyside, England         105      0.8768   \n",
              "2        Glasgow, Strathclyde, Scotland          97      0.9647   \n",
              "3   Stourbridge, West Midlands, England          13      0.7369   \n",
              "4  Stockton-on-Tees, Cleveland, England         139      0.8834   \n",
              "\n",
              "  political_leaning_label      price_label  \\\n",
              "0                 liberal               1d   \n",
              "1            conservative       ½ d<SEP>1d   \n",
              "2            conservative  3 ½ d<SEP>4 ½ d   \n",
              "3                     NaN              NaN   \n",
              "4                 liberal              ½ d   \n",
              "\n",
              "                                                text  \n",
              "0  NEW FASHIONS.  BELL (V, SON,  28 & 30, MANCHES...  \n",
              "1  LOANS To THE COUNCIL.  At a meeting of the Liv...  \n",
              "2  J. K. DONALD & W. NEVILLE  B- • - • ---EG to i...  \n",
              "3  TOBACCOS,  AT TEX  OLE ESTABLISH EI) S ITO FIE...  \n",
              "4  IT OF CHILDREN  YOLIFFE.  ice Court on Tuesday...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f466a1b4-127c-40f5-aafb-dab466be45af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>publication_code</th>\n",
              "      <th>issue_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>newspaper_title</th>\n",
              "      <th>data_provider</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>location</th>\n",
              "      <th>word_count</th>\n",
              "      <th>ocrquality</th>\n",
              "      <th>political_leaning_label</th>\n",
              "      <th>price_label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>209</td>\n",
              "      <td>3077</td>\n",
              "      <td>512</td>\n",
              "      <td>art0058</td>\n",
              "      <td>Nelson Chronicle, Colne Observer, and Clithero...</td>\n",
              "      <td>British Library Living with Machines Project</td>\n",
              "      <td>1899-05-12</td>\n",
              "      <td>1899</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>Nelson, Lancashire, England</td>\n",
              "      <td>160</td>\n",
              "      <td>0.9748</td>\n",
              "      <td>liberal</td>\n",
              "      <td>1d</td>\n",
              "      <td>NEW FASHIONS.  BELL (V, SON,  28 &amp; 30, MANCHES...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352</td>\n",
              "      <td>3040</td>\n",
              "      <td>1210</td>\n",
              "      <td>art0150</td>\n",
              "      <td>The Birkenhead News and Wirral General Adverti...</td>\n",
              "      <td>British Library Living with Machines Project</td>\n",
              "      <td>1910-12-10</td>\n",
              "      <td>1910</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>Birkenhead, Merseyside, England</td>\n",
              "      <td>105</td>\n",
              "      <td>0.8768</td>\n",
              "      <td>conservative</td>\n",
              "      <td>½ d&lt;SEP&gt;1d</td>\n",
              "      <td>LOANS To THE COUNCIL.  At a meeting of the Liv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>227</td>\n",
              "      <td>3089</td>\n",
              "      <td>426</td>\n",
              "      <td>art0036</td>\n",
              "      <td>Glasgow Courier.</td>\n",
              "      <td>British Library Living with Machines Project</td>\n",
              "      <td>1855-04-26</td>\n",
              "      <td>1855</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>Glasgow, Strathclyde, Scotland</td>\n",
              "      <td>97</td>\n",
              "      <td>0.9647</td>\n",
              "      <td>conservative</td>\n",
              "      <td>3 ½ d&lt;SEP&gt;4 ½ d</td>\n",
              "      <td>J. K. DONALD &amp; W. NEVILLE  B- • - • ---EG to i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>293</td>\n",
              "      <td>2974</td>\n",
              "      <td>312</td>\n",
              "      <td>art0014</td>\n",
              "      <td>The Stourbridge Observer, Cradley Heath, Hales...</td>\n",
              "      <td>British Library Living with Machines Project</td>\n",
              "      <td>1887-03-12</td>\n",
              "      <td>1887</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>Stourbridge, West Midlands, England</td>\n",
              "      <td>13</td>\n",
              "      <td>0.7369</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TOBACCOS,  AT TEX  OLE ESTABLISH EI) S ITO FIE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>449</td>\n",
              "      <td>3074</td>\n",
              "      <td>818</td>\n",
              "      <td>art0103</td>\n",
              "      <td>The North-Eastern Weekly Gazette.</td>\n",
              "      <td>British Library Living with Machines Project</td>\n",
              "      <td>1894-08-18</td>\n",
              "      <td>1894</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>Stockton-on-Tees, Cleveland, England</td>\n",
              "      <td>139</td>\n",
              "      <td>0.8834</td>\n",
              "      <td>liberal</td>\n",
              "      <td>½ d</td>\n",
              "      <td>IT OF CHILDREN  YOLIFFE.  ice Court on Tuesday...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f466a1b4-127c-40f5-aafb-dab466be45af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f466a1b4-127c-40f5-aafb-dab466be45af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f466a1b4-127c-40f5-aafb-dab466be45af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ef852fe-52ea-4b44-be5b-fb596d459474\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ef852fe-52ea-4b44-be5b-fb596d459474')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ef852fe-52ea-4b44-be5b-fb596d459474 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_small",
              "summary": "{\n  \"name\": \"df_small\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97,\n        \"min\": 209,\n        \"max\": 449,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          352,\n          449,\n          227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publication_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 2974,\n        \"max\": 3089,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3040,\n          3074,\n          3089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 362,\n        \"min\": 312,\n        \"max\": 1210,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1210,\n          818,\n          426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"art0150\",\n          \"art0103\",\n          \"art0036\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newspaper_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The Birkenhead News and Wirral General Advertiser.\",\n          \"The North-Eastern Weekly Gazette.\",\n          \"Glasgow Courier.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_provider\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"British Library Living with Machines Project\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1910-12-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 1855,\n        \"max\": 1910,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1910\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 3,\n        \"max\": 12,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 10,\n        \"max\": 26,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Birkenhead, Merseyside, England\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56,\n        \"min\": 13,\n        \"max\": 160,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocrquality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09538425970777359,\n        \"min\": 0.7369,\n        \"max\": 0.9748,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"political_leaning_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"conservative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u00bd d<SEP>1d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"LOANS To THE COUNCIL.  At a meeting of the Livetpoul City Council on NNedneaday a recommendation that \\u00a36,435 be. lent to the Hoylake and IVeist Kirby Diatriet Council at tutere.at at the rate of ..e3 17a. bd. per cent, per annum for varying periuda not exceeding thirty years, repayable by equal annual instalnienta of principal and intereet combined was tonaidered.  Mr. Dart remarked that he wbb gLad they had got 2s. ed. more than on the occasion of the laet loau, and he was burs that if the Finance Committee were a little firmer they would get, at all events, 4 per cent. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def apply_completions(item: pd.Series,\n",
        "                      system_message: str,\n",
        "                      user_message: str,\n",
        "                      text_column: str = 'text') -> str:\n",
        "  \"\"\"\n",
        "  Function that appl\n",
        "  Argument:\n",
        "    item (pd.Series): row from a pandas Dataframe\n",
        "    system_message (str): system prompt, specifies how the system\n",
        "      should behave in\n",
        "    user_message (str): user prompt, give instruction how to\n",
        "      process each historical. the documents itself will be append\n",
        "      from the 'text_column' argument\n",
        "    text_column (str): name of the text column\n",
        "  \"\"\"\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_message}\n",
        "      ]\n",
        "  messages[1]['content'] += f\"\\n\\n###{item[text_column]}###\"\n",
        "  return  get_completion(messages)"
      ],
      "metadata": {
        "id": "FJiND9t_dkE0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas() # use tqdm to view progress\n",
        "\n",
        "system_message = \"\"\"You are an helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper articles attentively and extract the required information.\n",
        "    Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "    Don't make thigs up! If the information is not in the article then just say 'Dunno'\"\"\"\n",
        "user_message = \"Summarize the article content in one sentence.\"\n",
        "\n",
        "df_small['completion'] =  df_small.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)"
      ],
      "metadata": {
        "id": "nUEjoux9Y3ZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cbc046-6e1d-4136-a691-a4d555995e1c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the summaries\n",
        "df_small['completion']"
      ],
      "metadata": {
        "id": "n54N-ySxjuN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f232aa-f100-495e-afca-fe562a210a6a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Here is a summary of the article content in on...\n",
              "1    The Livetpoul City Council considered a recomm...\n",
              "2    Here is a summary of the article content in on...\n",
              "3    The article appears to be an advertisement ann...\n",
              "4    Here is a summary of the article in one senten...\n",
              "Name: completion, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Biography as microgenre"
      ],
      "metadata": {
        "id": "ov1ySBNokZmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.sample(10, random_state=1984).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wKWWeBVXoFaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"You are an helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper articles attentively and extract structured information.\n",
        "    Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "    Don't make thigs up!\"\"\"\n",
        "\n",
        "\n",
        "user_message = \"\"\"Who are the characters portrayed in the article?\n",
        "    Extract biographical from a newspaper article.\n",
        "    For each identified person return a nested Python dictionary with the key equal to the name of the individual.\n",
        "    The values conist of dictionaries that record specific attributes such as age, gender, nationality, profession ,place of birth etc.\n",
        "    The format has to be a Python dictionary, do not add extra text!\"\"\""
      ],
      "metadata": {
        "id": "xAYqIGPOheVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small['completion'] =  df_small.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)\n"
      ],
      "metadata": {
        "id": "cDw5FzAta9Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff168f21-7093-4a47-deb9-d99284620a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 20%|██        | 2/10 [00:04<00:17,  2.15s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 30%|███       | 3/10 [00:08<00:20,  2.86s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 40%|████      | 4/10 [00:12<00:20,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 50%|█████     | 5/10 [00:15<00:15,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 60%|██████    | 6/10 [00:22<00:18,  4.68s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 70%|███████   | 7/10 [00:36<00:22,  7.53s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 80%|████████  | 8/10 [00:41<00:13,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 90%|█████████ | 9/10 [00:42<00:05,  5.08s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 10/10 [00:49<00:00,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 10/10 [01:06<00:00,  6.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_small['completion'][5]"
      ],
      "metadata": {
        "id": "BJGmFs9Qq_Tu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5c0f06dc-f97c-4374-f62f-59808c0f1737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here is the extracted information in a Python dictionary format:\\n\\n{\\n    'Rev. Mr. Rhodes': {\\n        'profession': 'clergy',\\n        'nationality': 'British'\\n    },\\n    'Mr. John Haling': {\\n        'profession': 'Offlay Arnie',\\n        'nationality': 'British'\\n    },\\n    'Mr. William Steele': {\\n        'profession': 'Flitch of Bacon',\\n        'nationality': 'British'\\n    },\\n    'Mr. Reeves': {\\n        'profession': 'host',\\n        'nationality': 'British'\\n    },\\n    'Mrs. Reeves': {\\n        'profession': 'hostess',\\n        'nationality': 'British'\\n    },\\n    'Mr. Warburton': {\\n        'profession':'surgeon',\\n        'nationality': 'British'\\n    },\\n    'Mr. Palmer': {\\n        'profession':'surgeon',\\n        'nationality': 'British'\\n    }\\n}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(df_small['completion'][5].split('format:\\n\\n')[-1].strip())"
      ],
      "metadata": {
        "id": "tS6AD3QbpL0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e5feb8-fe69-403f-ee48-68ec9a869bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Rev. Mr. Rhodes': {'profession': 'clergy', 'nationality': 'British'},\n",
              " 'Mr. John Haling': {'profession': 'Offlay Arnie', 'nationality': 'British'},\n",
              " 'Mr. William Steele': {'profession': 'Flitch of Bacon',\n",
              "  'nationality': 'British'},\n",
              " 'Mr. Reeves': {'profession': 'host', 'nationality': 'British'},\n",
              " 'Mrs. Reeves': {'profession': 'hostess', 'nationality': 'British'},\n",
              " 'Mr. Warburton': {'profession': 'surgeon', 'nationality': 'British'},\n",
              " 'Mr. Palmer': {'profession': 'surgeon', 'nationality': 'British'}}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(df_small['completion'][4].split('format:\\n\\n')[-1].strip())"
      ],
      "metadata": {
        "id": "zE2fO-wRrL9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee5a1ad-9835-41c9-becf-2e86153bd99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Robert Thompson': {'age': None,\n",
              "  'gender': None,\n",
              "  'nationality': None,\n",
              "  'profession': 'S.P.C.C. Inspector',\n",
              "  'place_of_birth': 'Aycliffe'},\n",
              " 'Mr. J. T. Proud': {'age': None,\n",
              "  'gender': None,\n",
              "  'nationality': None,\n",
              "  'profession': 'S.P.C.C. Inspector',\n",
              "  'place_of_birth': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(df_small['completion'][2].split('format:\\n\\n')[-1].strip())"
      ],
      "metadata": {
        "id": "nyZ-yv8brFdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14448a9-479c-4dc5-e2db-d2e6585a8d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'J. K. Donald': {'name': 'J. K. Donald',\n",
              "  'profession': 'Watchmaker and Jeweller'},\n",
              " 'W. Neville': {'name': 'W. Neville', 'profession': 'Watchmaker and Jeweller'}}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: OCR correction"
      ],
      "metadata": {
        "id": "CWAog9xdpG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_small_bad_ocr = df.sort_values('ocrquality')[:5]"
      ],
      "metadata": {
        "id": "G5N8e2qdpKBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"\"\"Transcribe the text and correct typos and errors in the text caused by bad optical character recognition (OCR).\n",
        "Do not add any information that is not in the original text!\"\"\"\n",
        "\n",
        "df_small_bad_ocr['completion'] = df_small_bad_ocr.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)\n"
      ],
      "metadata": {
        "id": "4JXH_oypolYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc25028-1f1f-479d-a264-aeb0e81cc351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 40%|████      | 2/5 [00:03<00:05,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 60%|██████    | 3/5 [00:07<00:05,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 80%|████████  | 4/5 [00:12<00:03,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 5/5 [00:15<00:00,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 5/5 [00:33<00:00,  6.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small_bad_ocr.iloc[0]['text'])"
      ],
      "metadata": {
        "id": "wjFbCSDYtNx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaebe67-1a35-4128-c936-b1b1ac365663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.9,oUMPLlAZill—dorr Walnut. annininiiire ‘.7 in nacallent condition. a Ibn. 1.41:.ND; Rigiten porkatzili tu!l drawn . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small_bad_ocr.iloc[0]['completion'])"
      ],
      "metadata": {
        "id": "XLsWShc7tKGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc745dc7-f62a-454b-c797-6e392bcbda32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'll transcribe the text and correct any typos or OCR errors. Here is the corrected text:\n",
            "\n",
            "###4.9, Upland Plum Lane - Door Walnut, in excellent condition, $141,000; Righten porkatzili to view. ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small_bad_ocr.iloc[4]['text'])"
      ],
      "metadata": {
        "id": "6rc0U8WqsXiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e801de6-1eb6-49c3-bfc3-c55035f9665d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaEWAN & WALLACH.  itulilliSUA KILL). EMITS AGICtiTa LAN' VALUERS - v 34, H AMILTUN squARE, 1.7b-lopti 1:4 ul6  AkA;ll  BAND AND SMITH ESTATE AlitE,NTd, SUBNEWILS V AlAi MS, 71. LORD-STILLET LIVFX.POOI4 Div= th4truusa Qrle LibrelWaoots LIMP POOL sod DlValot. Wine, r Idiom i4colli*Mor4di. Tolpphoos WIT Biak. 391 NEVI OliarrialieliOAD, Rock Parry.— &ask etabia or akau Yard 8.401 3s. 6d  WEls. KIRBY A/CD HOYLAXE 7ar - OE LET OR SOLD AMY TO W. F. B\"v-\"• ESTArE AGENT AND VALUER 3, GRANGE ROAD, wEer ILEXBY Telopkrme Hoyaak• 89. gry1684.1.7  Itia•bllabed 1/0. QU FAN AND FOSTER  INSTATE AGENTS & SAMBAS. 2 8013TH STICSAT,LIVSEPOOL Warsaw \" ti4c.o4 TellebOute. Zink 4ii6 1177:1  J0H.30  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small_bad_ocr.iloc[4]['completion'])"
      ],
      "metadata": {
        "id": "Y5BxeDnttYZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c4a399-3390-4179-9f8e-dcfc40ff5875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the transcribed text with corrections for typos and OCR errors:\n",
            "\n",
            "###Maewan & Wallach. It is said that Maewan & Wallach will kill). Emits a Gigantic Lan' Valuers - 34, Hamilton Square, 1.7b-loft, 1:4 ul6, Akall Band and Smith Estate Alite, Nt, Subnewils Val, 71. Lord-Stillet Livpool. Pool Div= the true use of the Quadrille Librel Waouts Limp Pool and Divalot. Wine, or Idiom icoll*Mor4di. Topphoos Wit Biak. 391 Neville Road, Rock Ferry.— Ask etabia or akau Yard 8.401 3s. 6d. Wells. Kirby & Co. Hoylake - To Let or Sold Amy to W. F. B\"v-\"• Estate Agent and Valuer 3, Grange Road, Weaver Ilexby. Telephone Hoylake 89. Gry1684.1.7. It is said that 1/0. Qu Fan and Foster Instate Agents & Sambas. 2 8013th Sticsat, Livsepool. Warsaw \" ti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_small_bad_ocr.to_csv('newspaper_ocr_corrected.csv')"
      ],
      "metadata": {
        "id": "BpChnh_7q-gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining document filtering and targeted prompting\n",
        "\n",
        "Below, we combine many the things we covered in the previous notebook. Instead of running an LLM on all the documents, we use regular expressions to select a relevant subset of newspaper articles and use the LLMs to extract structured information."
      ],
      "metadata": {
        "id": "7-tHuljcsSoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = re.compile(r'\\baccident[s]{0,1}\\b',re.I) # compile a regex\n",
        "df_kw_sample = df[df.apply(lambda x: bool(pattern.findall(x.text)), axis=1)] # get only rows that match the regex\n",
        "\n",
        "# define the user message we retain the system message from previous examples\n",
        "user_message = \"\"\"Does the newspaper describe a historical accident? If not return an empty Python list'.\n",
        "If it does describe an accident extract, information on the people involved in the accident.\n",
        "Return a list of Python dictionaries. For each dictionary the key is equal to the name of the person.\n",
        "The values list charactertistics of this person such a gender, age and occupation.\n",
        "Only return the Python list and no additional text!\n",
        "\"\"\"\n",
        "\n",
        "# apply messages\n",
        "df_kw_sample['completion'] = df_kw_sample.progress_apply(apply_completions, user_message=user_message, system_message=system_message, axis=1)\n",
        "# save outputs\n",
        "df_kw_sample.to_csv('accidents.csv')"
      ],
      "metadata": {
        "id": "Xg5Llg_7wOmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ff0980-1966-49e2-9053-50060ff91a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            " 67%|██████▋   | 2/3 [00:03<00:01,  1.79s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 3/3 [00:03<00:00,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "100%|██████████| 3/3 [00:05<00:00,  1.91s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_kw_sample['completion']"
      ],
      "metadata": {
        "id": "VsKxeC4RtrEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0232bad-016f-4a78-a0bc-f06dbb88fcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51    [\\n    {\"Chadder\": {\"gender\": \"male\", \"age\": \"...\n",
              "79                                                   []\n",
              "80    [\\n    {'Postman': {'gender':'male', 'age': 'u...\n",
              "Name: completion, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(df_kw_sample.iloc[0]['completion'])"
      ],
      "metadata": {
        "id": "Pd_ZL0orx64i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5c67bf-c1a4-4c2d-b26c-80500d1af1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Chadder': {'gender': 'male',\n",
              "   'age': 'unknown',\n",
              "   'occupation': 'naval reserves'}},\n",
              " {'James Edmund Flood': {'gender': 'male',\n",
              "   'age': '18',\n",
              "   'occupation': 'unknown'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Experiment with your own system and user message! Have fun :-)"
      ],
      "metadata": {
        "id": "FzavYR10sI_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "OyrtAOQ24cJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fin."
      ],
      "metadata": {
        "id": "XzdNxsZPsKr5"
      }
    }
  ]
}